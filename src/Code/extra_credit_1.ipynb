{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import os, sys\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rel_path(file_name):\n",
    "    absolutepath = os.path.abspath('')\n",
    "    #print(absolutepath)\n",
    "    fileDirectory = os.path.dirname(absolutepath)\n",
    "    file_path = os.path.join(fileDirectory, 'Data/' + str(file_name))   \n",
    "    #print(file_path)\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS --> code I used to make preprocess input and generate dataframe \n",
    "# takes in a raw xml file, extracts the orthographic form & POS tag, and returns it as a bag of words df \n",
    "def make_dataframe(soup, predictor, output):\n",
    "    chunks = soup.find_all(\"chunk\")\n",
    "    ctag = soup.find_all(\"ctag\")\n",
    "    \n",
    "    # make bow \n",
    "        # all lowercase \n",
    "        # add <s> and </s> markers \n",
    "    context_window_list = []\n",
    "    for chunk in chunks:\n",
    "        forms = chunk.find_all(predictor) #this will either be the orth form OR the lemma \n",
    "        for i in range(0, len(forms)):\n",
    "            row = []\n",
    "            target_word = forms[i].get_text()\n",
    "            # get three words before:\n",
    "            for j in reversed(range(1,4)):\n",
    "                if (i-j) < 0: row.append(\"<s>\") # add beginning of sentence marker \n",
    "                else: row.append(forms[i-j].get_text())\n",
    "            # add target word\n",
    "            row.append(target_word)\n",
    "            # get three words after:\n",
    "            for j in range(1,4):\n",
    "                if (i+j) > len(forms) - 1: row.append(\"</s>\") # add end of sentence marker \n",
    "                else: row.append(forms[i+j].get_text())\n",
    "\n",
    "            context_window_list.append(row)\n",
    "        \n",
    "    # get pos tags \n",
    "    classes = []\n",
    "    for i in range(0, len(ctag)):\n",
    "        if output == \"ctag\": ct = ctag[i].get_text() #obtain entire ctag \n",
    "        else: ct = ctag[i].get_text().split(\":\")[0] # if POS tag specified --> get the first tag  \n",
    "        classes.append(ct)\n",
    "    \n",
    "    #make bow df \n",
    "    context_window = np.array(context_window_list)\n",
    "    context_window = np.transpose(context_window)\n",
    "    data = {\"a1\": context_window[0], \"a2\": context_window[1], \"a3\": context_window[2], \n",
    "       \"a4\": context_window[3], \"a5\": context_window[4], \"a6\": context_window[5], \n",
    "       \"a7\": context_window[6], \"class\": classes}\n",
    "    df = pd.DataFrame(data)\n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS <-- prepping train & test sets \n",
    "# prepare training & test sets \n",
    "#load train and validate datasets in dataframes\n",
    "train = get_rel_path(\"train.xml\")\n",
    "train = open(train, 'r')\n",
    "train_contents = train.read()\n",
    "train_soup = BeautifulSoup(train_contents, 'xml')\n",
    "train_df = make_dataframe(train_soup)\n",
    "\n",
    "validate = get_rel_path(\"validate.xml\")\n",
    "validate = open(validate, 'r')\n",
    "validate_contents = validate.read()\n",
    "validate_soup = BeautifulSoup(validate_contents, 'xml')\n",
    "validate_df = make_dataframe(validate_soup)\n",
    "\n",
    "test = get_rel_path(\"Data/test-full-1.xml\")\n",
    "test = open(test, 'r')\n",
    "test_contents = test.read()\n",
    "test_soup = BeautifulSoup(test_contents, 'xml')\n",
    "test_df = make_dataframe(test_soup)\n",
    "\n",
    "# TEST 1: predictor = orth form ; output = full ctag\n",
    "train1_df = make_dataframe(train_soup, predictor=\"orth\", output=\"ctag\")\n",
    "validate1_df = make_dataframe(validate_soup, predictor=\"orth\", output=\"ctag\")\n",
    "test1_df = make_dataframe(test_soup, predictor=\"orth\", output = \"ctag\")\n",
    "# export to csv for easier loading:\n",
    "train1_df.to_csv(get_rel_path(\"train1_ec1.csv\"), index = False)\n",
    "validate1_df.to_csv(get_rel_path(\"validate1_ec1.csv\"), index = False)\n",
    "test1_df.to_csv(get_rel_path(\"test1_ec1.csv\"), index = False)\n",
    "\n",
    "# TEST 2: predictor = lemma; output = POS tag \n",
    "train2_df = make_dataframe(train_soup, predictor=\"base\", output=\"pos\")\n",
    "validate2_df = make_dataframe(validate_soup, predictor=\"base\", output=\"pos\")\n",
    "test2_df = make_dataframe(test_soup, predictor=\"base\", output = \"pos\")\n",
    "# export to csv for easier loading:\n",
    "train2_df.to_csv(get_rel_path(\"train2_ec1.csv\"), index = False)\n",
    "validate2_df.to_csv(get_rel_path(\"validate2_ec1.csv\"), index = False)\n",
    "test2_df.to_csv(get_rel_path(\"test2_ec1.csv\"), index = False)\n",
    "\n",
    "# TEST 3: predictor = lemma; output = full tag \n",
    "train3_df = make_dataframe(train_soup, predictor=\"base\", output=\"ctag\")\n",
    "validate3_df = make_dataframe(validate_soup, predictor=\"base\", output=\"ctag\")\n",
    "test3_df = make_dataframe(test_soup, predictor=\"base\", output = \"ctag\")\n",
    "# export to csv for easier loading:\n",
    "train3_df.to_csv(get_rel_path(\"train3_ec1.csv\"), index = False)\n",
    "validate3_df.to_csv(get_rel_path(\"validate3_ec1.csv\"), index = False)\n",
    "test3_df.to_csv(get_rel_path(\"test3_ec1.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS --> LOAD train & validate datasets from csv files\n",
    "# Test 1 \n",
    "train1_df = pd.read_csv(get_rel_path(\"train1_ec1.csv\"))\n",
    "validate1_df = pd.read_csv(get_rel_path(\"validate1_ec1.csv\"))\n",
    "test1_df = pd.read_csv(get_rel_path(\"test1_ec1.csv\"))\n",
    "\n",
    "# Test 2\n",
    "train2_df = pd.read_csv(get_rel_path(\"train2_ec1.csv\"))\n",
    "validate2_df = pd.read_csv(get_rel_path(\"validate2_ec1.csv\"))\n",
    "test2_df = pd.read_csv(get_rel_path(\"test2_ec1.csv\"))\n",
    "\n",
    "# Test 3\n",
    "train3_df = pd.read_csv(get_rel_path(\"train3_ec1.csv\"))\n",
    "validate3_df = pd.read_csv(get_rel_path(\"validate3_ec1.csv\"))\n",
    "test3_df = pd.read_csv(get_rel_path(\"test3_ec1.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       a1       a2       a3       a4       a5       a6       a7  \\\n",
      "0     <s>      <s>      <s>   Zabiję      cię        ,    jeśli   \n",
      "1     <s>      <s>   Zabiję      cię        ,    jeśli  umrzesz   \n",
      "2     <s>   Zabiję      cię        ,    jeśli  umrzesz        !   \n",
      "3  Zabiję      cię        ,    jeśli  umrzesz        !        \"   \n",
      "4     cię        ,    jeśli  umrzesz        !        \"     </s>   \n",
      "5       ,    jeśli  umrzesz        !        \"     </s>     </s>   \n",
      "6   jeśli  umrzesz        !        \"     </s>     </s>     </s>   \n",
      "7     <s>      <s>      <s>   Cieszy     fakt        ,       że   \n",
      "8     <s>      <s>   Cieszy     fakt        ,       że    Royal   \n",
      "9     <s>   Cieszy     fakt        ,       że    Royal    Canin   \n",
      "\n",
      "                        class  \n",
      "0             fin:sg:pri:perf  \n",
      "1  ppron12:sg:acc:m1:sec:nakc  \n",
      "2                      interp  \n",
      "3                        comp  \n",
      "4             fin:sg:sec:perf  \n",
      "5                      interp  \n",
      "6                      interp  \n",
      "7           fin:sg:ter:imperf  \n",
      "8             subst:sg:nom:m3  \n",
      "9                      interp  \n",
      "            a1      a2      a3      a4      a5      a6      a7   class\n",
      "count   972588  972587  972587  972587  972590  972591  972592  972600\n",
      "unique  110130  115604  125745  126215  116249  110899  105735     896\n",
      "top        <s>     <s>     <s>       .       .    </s>    </s>  interp\n",
      "freq    204199  136983   68530   72728   72724  136983  204199  178643\n",
      "\n",
      "      a1       a2       a3       a4      a5      a6      a7    class\n",
      "0    <s>      <s>      <s>    zabić      ty       ,   jeśli      fin\n",
      "1    <s>      <s>    zabić       ty       ,   jeśli  umrzeć  ppron12\n",
      "2    <s>    zabić       ty        ,   jeśli  umrzeć       !   interp\n",
      "3  zabić       ty        ,    jeśli  umrzeć       !       \"     comp\n",
      "4     ty        ,    jeśli   umrzeć       !       \"    </s>      fin\n",
      "5      ,    jeśli   umrzeć        !       \"    </s>    </s>   interp\n",
      "6  jeśli   umrzeć        !        \"    </s>    </s>    </s>   interp\n",
      "7    <s>      <s>      <s>  cieszyć    fakt       ,      że      fin\n",
      "8    <s>      <s>  cieszyć     fakt       ,      że   Royal    subst\n",
      "9    <s>  cieszyć     fakt        ,      że   Royal   Canin   interp\n",
      "            a1      a2      a3      a4      a5      a6      a7   class\n",
      "count   972600  972600  972600  972600  972600  972600  972600  972600\n",
      "unique   42873   44619   48635   48855   47603   46125   44575      35\n",
      "top        <s>     <s>     <s>       .       .    </s>    </s>   subst\n",
      "freq    204199  136983   68530   72728   72724  136983  204199  265749\n",
      "\n",
      "      a1       a2       a3       a4      a5      a6      a7  \\\n",
      "0    <s>      <s>      <s>    zabić      ty       ,   jeśli   \n",
      "1    <s>      <s>    zabić       ty       ,   jeśli  umrzeć   \n",
      "2    <s>    zabić       ty        ,   jeśli  umrzeć       !   \n",
      "3  zabić       ty        ,    jeśli  umrzeć       !       \"   \n",
      "4     ty        ,    jeśli   umrzeć       !       \"    </s>   \n",
      "5      ,    jeśli   umrzeć        !       \"    </s>    </s>   \n",
      "6  jeśli   umrzeć        !        \"    </s>    </s>    </s>   \n",
      "7    <s>      <s>      <s>  cieszyć    fakt       ,      że   \n",
      "8    <s>      <s>  cieszyć     fakt       ,      że   Royal   \n",
      "9    <s>  cieszyć     fakt        ,      że   Royal   Canin   \n",
      "\n",
      "                        class  \n",
      "0             fin:sg:pri:perf  \n",
      "1  ppron12:sg:acc:m1:sec:nakc  \n",
      "2                      interp  \n",
      "3                        comp  \n",
      "4             fin:sg:sec:perf  \n",
      "5                      interp  \n",
      "6                      interp  \n",
      "7           fin:sg:ter:imperf  \n",
      "8             subst:sg:nom:m3  \n",
      "9                      interp  \n",
      "            a1      a2      a3      a4      a5      a6      a7   class\n",
      "count   972600  972600  972600  972600  972600  972600  972600  972600\n",
      "unique   42873   44619   48635   48855   47603   46125   44575     896\n",
      "top        <s>     <s>     <s>       .       .    </s>    </s>  interp\n",
      "freq    204199  136983   68530   72728   72724  136983  204199  178643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# combine validate_df + train_df to form the train test set:\n",
    "# Test 1: predictor = orth form ; output = full ctag\n",
    "frames = [train1_df, validate1_df]\n",
    "train1_df = pd.concat(frames)\n",
    "print(train1_df.head(n=10))\n",
    "print(train1_df.describe())\n",
    "print()\n",
    "\n",
    "# Test 2: predictor = lemma; output = POS tag \n",
    "frames = [train2_df, validate2_df]\n",
    "train2_df = pd.concat(frames)\n",
    "print(train2_df.head(n=10))\n",
    "print(train2_df.describe())\n",
    "print()\n",
    "\n",
    "# Test 3: predictor = lemma; output = full tag \n",
    "frames = [train3_df, validate3_df]\n",
    "train3_df = pd.concat(frames)\n",
    "print(train3_df.head(n=10))\n",
    "print(train3_df.describe())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# Transform the training & validation data from symbols to numbers \n",
    "# Takes in a df of the correct format & returns a numerical representation of the data \n",
    "def make_vectors(df):\n",
    "    labels = np.asarray(df['class'].astype(\"category\").cat.codes.tolist())\n",
    "    print('There are {} classes in this data.'.format(len(list(set(labels)))))\n",
    "    labels[:5]\n",
    "    \n",
    "    X_vals = df.drop(columns=['class']).values\n",
    "    #print(\"X Values:\")\n",
    "    #print(X_vals)\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(X_vals.ravel())\n",
    "    X = le.transform(X_vals.ravel())\n",
    "    X = X.reshape(len(X_vals), -1)\n",
    "    len(list(set(X_vals.ravel())))\n",
    "    #print(\"\\nNumerical representation:\")\n",
    "    #print(X)\n",
    "    return X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 896 classes (POS labels) in this data.\n",
      "There are 757 classes (POS labels) in this data.\n",
      "There are 35 classes (POS labels) in this data.\n",
      "There are 35 classes (POS labels) in this data.\n",
      "There are 757 classes (POS labels) in this data.\n",
      "There are 896 classes (POS labels) in this data.\n"
     ]
    }
   ],
   "source": [
    "# Transform the data from symbols to numbers\n",
    "# Test 1 : predictor = orth form ; output = full ctag\n",
    "X_train1 = make_vectors(train1_df)\n",
    "X_test1 = make_vectors(test1_df)\n",
    "# Test 2 : predictor = lemma; output = POS tag \n",
    "X_train2 = make_vectors(train2_df)\n",
    "X_test2 = make_vectors(test2_df)\n",
    "# Test 3 : predictor = lemma; output = full tag \n",
    "X_test3 = make_vectors(test3_df)\n",
    "X_train3 = make_vectors(train3_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN and EVALUATE THE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to take as input training and testing vectors and labels\n",
    "# Allow this to be extensible to let multiple classifiers be used here\n",
    "def buildClassifiers(clf, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average=\"micro\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"micro\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"micro\")\n",
    "\n",
    "    return f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the classifiers \n",
    "def train_and_evaluate(X_train, X_test, train_df, test_df):\n",
    "    names = ['Naive_Bayes', 'Decision_Tree']\n",
    "    classifiers = [GaussianNB(), \n",
    "                   DecisionTreeClassifier(random_state=42)]\n",
    "    aList, bList, cList = list(), list(), list()\n",
    "    itr = 0\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        print('Now classifying', name)\n",
    "        y_train = train_df[\"class\"]\n",
    "        y_test = test_df[\"class\"]\n",
    "        f1, precision, recall = buildClassifiers(clf, X_train, X_test,  \n",
    "                                                 y_train = y_train, y_test = y_test)\n",
    "        aList.append(f1)\n",
    "        bList.append(precision)\n",
    "        cList.append(recall)\n",
    "\n",
    "        print(\"\\tF1 for {}:\\t\\t\".format(name), aList[itr])\n",
    "        print(\"\\tPrecision for {}:\\t\".format(name), bList[itr])\n",
    "        print(\"\\tRecall for {}:\\t\\t\".format(name), cList[itr])\n",
    "        print()\n",
    "        itr = itr + 1 \n",
    "    return aList, bList, cList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: predictor = orth form ; output = full ctag\n",
      "Now classifying Naive_Bayes\n",
      "\tF1 for Naive_Bayes:\t\t 0.1662899885967404\n",
      "\tPrecision for Naive_Bayes:\t 0.1662899885967404\n",
      "\tRecall for Naive_Bayes:\t\t 0.1662899885967404\n",
      "\n",
      "Now classifying Decision_Tree\n",
      "\tF1 for Decision_Tree:\t\t 0.17127119586024625\n",
      "\tPrecision for Decision_Tree:\t 0.17127119586024625\n",
      "\tRecall for Decision_Tree:\t\t 0.17127119586024625\n",
      "\n",
      "\n",
      "Test 2: predictor = lemma; output = POS tag \n",
      "Now classifying Naive_Bayes\n",
      "\tF1 for Naive_Bayes:\t\t 0.2727272727272727\n",
      "\tPrecision for Naive_Bayes:\t 0.2727272727272727\n",
      "\tRecall for Naive_Bayes:\t\t 0.2727272727272727\n",
      "\n",
      "Now classifying Decision_Tree\n",
      "\tF1 for Decision_Tree:\t\t 0.3104609469233841\n",
      "\tPrecision for Decision_Tree:\t 0.3104609469233841\n",
      "\tRecall for Decision_Tree:\t\t 0.3104609469233841\n",
      "\n",
      "\n",
      "Test 3: predictor = lemma; output = full tag \n",
      "Now classifying Naive_Bayes\n",
      "\tF1 for Naive_Bayes:\t\t 0.16782963447818766\n",
      "\tPrecision for Naive_Bayes:\t 0.16782963447818766\n",
      "\tRecall for Naive_Bayes:\t\t 0.16782963447818766\n",
      "\n",
      "Now classifying Decision_Tree\n",
      "\tF1 for Decision_Tree:\t\t 0.09685360602355578\n",
      "\tPrecision for Decision_Tree:\t 0.09685360602355576\n",
      "\tRecall for Decision_Tree:\t\t 0.09685360602355576\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.16782963447818766, 0.09685360602355578],\n",
       " [0.16782963447818766, 0.09685360602355576],\n",
       " [0.16782963447818766, 0.09685360602355576])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Test 1: predictor = orth form ; output = full ctag\")\n",
    "train_and_evaluate(X_train = X_train1, X_test = X_test1, train_df = train1_df, test_df = test1_df)\n",
    "print()\n",
    "print(\"Test 2: predictor = lemma; output = POS tag \")\n",
    "train_and_evaluate(X_train = X_train2, X_test = X_test2, train_df = train2_df, test_df = test2_df)\n",
    "print()\n",
    "print(\"Test 3: predictor = lemma; output = full tag \")\n",
    "train_and_evaluate(X_train = X_train3, X_test = X_test3, train_df = train3_df, test_df = test3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
